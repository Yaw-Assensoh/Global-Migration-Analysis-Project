# File: pages/6_Enhanced_Advanced_Forecasting.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.model_selection import TimeSeriesSplit
import io
from datetime import timedelta, datetime
import warnings
import pickle
import json
import os
from pathlib import Path
warnings.filterwarnings('ignore')

# Try to import Prophet (handle missing installation)
try:
    from prophet import Prophet
    from prophet.plot import plot_plotly, plot_components_plotly
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    st.sidebar.warning("‚ö†Ô∏è Prophet not installed. Install with: `pip install prophet`")

# Try to import ARIMA
try:
    from statsmodels.tsa.arima.model import ARIMA
    ARIMA_AVAILABLE = True
except ImportError:
    ARIMA_AVAILABLE = False
    st.sidebar.warning("‚ö†Ô∏è statsmodels not installed. Install with: `pip install statsmodels`")

# Try to import additional libraries for enhanced features
try:
    from scipy import stats
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    st.sidebar.warning("‚ö†Ô∏è SciPy not installed. Install with: `pip install scipy`")

# Set page config
st.set_page_config(
    page_title="Enhanced Migration Forecasting | Global Migration Analysis",
    page_icon="üìà",
    layout="wide"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 25px;
        border-radius: 10px;
        color: white;
        margin-bottom: 20px;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
        text-align: center;
    }
    .model-card {
        border-left: 5px solid #4CAF50;
        padding: 15px;
        background-color: #f9f9f9;
        margin: 10px 0;
        border-radius: 5px;
    }
    .warning-card {
        border-left: 5px solid #FF9800;
        padding: 15px;
        background-color: #FFF3E0;
        margin: 10px 0;
        border-radius: 5px;
    }
    .success-card {
        border-left: 5px solid #4CAF50;
        padding: 15px;
        background-color: #E8F5E9;
        margin: 10px 0;
        border-radius: 5px;
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
</style>
""", unsafe_allow_html=True)

# Title with enhanced header
st.markdown('<div class="main-header"><h1>üìà Enhanced Migration Forecasting</h1><p>Advanced multi-model forecasting with uncertainty quantification and ensemble methods</p></div>', unsafe_allow_html=True)

# Sidebar Configuration
st.sidebar.header("‚öôÔ∏è Forecasting Configuration")

# Load data function with caching
@st.cache_data
def load_migration_data():
    """Load and prepare migration data with enhanced time series"""
    try:
        # Create sample data with more realistic patterns
        np.random.seed(42)
        
        countries = ['United States', 'Germany', 'India', 'Nigeria', 'Japan', 'Brazil', 
                    'United Kingdom', 'France', 'China', 'Australia']
        
        # Generate synthetic time series data (2000-2025)
        all_data = []
        base_year = 2000
        end_year = 2025
        
        for country_idx, country in enumerate(countries):
            # Country-specific parameters
            if country in ['United States', 'Germany', 'United Kingdom', 'France', 'Australia']:
                # Developed countries: lower volatility, positive migration
                base_rate = np.random.uniform(2, 8)
                trend = np.random.uniform(0.01, 0.05)
                volatility = np.random.uniform(0.3, 0.8)
            elif country in ['India', 'Nigeria', 'Brazil']:
                # Developing countries: higher volatility, often negative migration
                base_rate = np.random.uniform(-2, 2)
                trend = np.random.uniform(-0.02, 0.02)
                volatility = np.random.uniform(0.8, 1.5)
            else:  # China, Japan
                # Stable/aging populations
                base_rate = np.random.uniform(-1, 1)
                trend = np.random.uniform(-0.03, 0.01)
                volatility = np.random.uniform(0.5, 1.0)
            
            # Add country-specific seasonality
            seasonality_amp = np.random.uniform(0.5, 2.0)
            
            for year in range(base_year, end_year + 1):
                # Time index
                t = year - base_year
                
                # Base trend
                value = base_rate + (trend * t)
                
                # Add seasonality (5-year cycles for policy changes)
                seasonality = seasonality_amp * np.sin(2 * np.pi * t / 5)
                
                # Add random noise with volatility
                noise = volatility * np.random.normal(0, 1)
                
                # Add structural breaks every 8-12 years
                if t > 0 and t % np.random.randint(8, 12) == 0:
                    value += np.random.uniform(-3, 3)
                
                # Combine all components
                migration_rate = value + seasonality + noise
                
                # Generate correlated metrics
                population = 1e6 * (1 + np.random.uniform(0.01, 0.03)) ** t
                gdp_growth = np.random.uniform(1, 5) + 0.1 * migration_rate
                fertility = max(1.0, 3.0 - 0.02 * t + 0.1 * np.random.normal(0, 1))
                
                all_data.append({
                    'ds': f'{year}-01-01',
                    'y': migration_rate,
                    'country': country,
                    'population': population,
                    'gdp_growth': gdp_growth,
                    'fertility': fertility,
                    'base_rate': base_rate,
                    'trend': trend,
                    'volatility': volatility
                })
        
        time_series_df = pd.DataFrame(all_data)
        time_series_df['ds'] = pd.to_datetime(time_series_df['ds'])
        
        # Create summary dataframe
        summary_df = pd.DataFrame({
            'Country': countries,
            'Avg_Migration_Rate': [np.mean(time_series_df[time_series_df['country'] == c]['y']) for c in countries],
            'Trend_Direction': ['Positive' if time_series_df[time_series_df['country'] == c]['trend'].iloc[0] > 0 else 'Negative' for c in countries],
            'Volatility': [time_series_df[time_series_df['country'] == c]['volatility'].iloc[0] for c in countries]
        })
        
        return summary_df, time_series_df
        
    except Exception as e:
        st.error(f"Error generating data: {e}")
        return pd.DataFrame(), pd.DataFrame()

# Load data
summary_df, time_series_df = load_migration_data()

# Model availability check
available_models = []
if PROPHET_AVAILABLE:
    available_models.append("Prophet")
if ARIMA_AVAILABLE:
    available_models.append("ARIMA")

# Always available models
available_models.extend(["Simple Exponential Smoothing", "Moving Average", "Linear Trend", "Ensemble"])

if not available_models:
    st.error("No forecasting models available. Please install at least one model library.")
    st.stop()

# Enhanced Sidebar Configuration
st.sidebar.subheader("üéØ Model Selection")
models_selected = st.sidebar.multiselect(
    "Select forecasting models:",
    available_models,
    default=["Prophet", "ARIMA", "Ensemble"] if "Prophet" in available_models and "ARIMA" in available_models else available_models[:2]
)

# Advanced Forecasting Parameters
st.sidebar.subheader("üìä Forecast Parameters")
forecast_years = st.sidebar.slider("Forecast Horizon (years):", 1, 15, 5)

# Multiple confidence levels
st.sidebar.subheader("üéØ Uncertainty Settings")
confidence_levels_selected = st.sidebar.multiselect(
    "Confidence Levels:",
    [68, 80, 95, 99],
    default=[80, 95],
    help="Select confidence intervals to display"
)

# Ensemble method selection
st.sidebar.subheader("ü§ù Ensemble Configuration")
ensemble_method = st.sidebar.selectbox(
    "Ensemble Method:",
    ["Simple Average", "Weighted by Accuracy", "Bayesian Average", "Median"],
    help="How to combine model forecasts"
)

# Backtesting settings
st.sidebar.subheader("üß™ Model Validation")
enable_backtesting = st.sidebar.checkbox("Enable Backtesting", value=True)
backtest_splits = st.sidebar.slider("Backtest Splits:", 3, 10, 5) if enable_backtesting else 3

# Country selection with metrics
st.sidebar.subheader("üåç Country Selection")
available_countries = sorted(time_series_df['country'].unique())

# Add country info to selection
country_info = {}
for country in available_countries:
    country_data = time_series_df[time_series_df['country'] == country]
    avg_rate = country_data['y'].mean()
    trend = "üìà" if country_data['trend'].iloc[0] > 0 else "üìâ"
    volatility = country_data['volatility'].iloc[0]
    country_info[country] = f"{country} {trend} (Avg: {avg_rate:.1f}, Vol: {volatility:.2f})"

selected_country = st.sidebar.selectbox(
    "Select Country:",
    available_countries,
    index=0,
    format_func=lambda x: country_info.get(x, x)
)

# Scenario parameters
st.sidebar.subheader("üé≠ Scenario Analysis")
with st.sidebar.expander("Economic Scenario"):
    scenario_growth = st.slider("GDP Growth Adjustment (%):", -30, 30, 0, 5)
    scenario_inflation = st.slider("Inflation Impact (%):", -20, 20, 0, 5)
    
with st.sidebar.expander("Policy Scenario"):
    policy_immigration = st.slider("Immigration Policy Impact:", -50, 50, 0, 10)
    policy_emigration = st.slider("Emigration Policy Impact:", -50, 50, 0, 10)

# Main content tabs
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìä Forecast Dashboard", 
    "üìà Model Comparison", 
    "üé≠ Scenario Analysis", 
    "üî¨ Advanced Metrics",
    "üìâ Uncertainty Analysis",
    "üíæ Export Results"
])

# Helper functions for enhanced forecasting
def calculate_prediction_intervals(forecast, std_dev, confidence_levels):
    """Calculate prediction intervals for multiple confidence levels"""
    intervals = {}
    z_scores = {68: 1.0, 80: 1.28, 95: 1.96, 99: 2.58}
    
    for level in confidence_levels:
        z = z_scores.get(level, 1.96)
        margin = z * std_dev
        intervals[level] = {
            'lower': forecast - margin,
            'upper': forecast + margin
        }
    
    return intervals

def create_ensemble_forecast(forecasts_dict, method="weighted", weights=None):
    """Create ensemble forecast using specified method"""
    if not forecasts_dict:
        return None
    
    forecast_dfs = []
    for model_name, forecast_data in forecasts_dict.items():
        if 'forecast_df' in forecast_data and forecast_data['forecast_df'] is not None:
            forecast_dfs.append((model_name, forecast_data['forecast_df']))
    
    if not forecast_dfs:
        return None
    
    # Align forecasts on common dates
    common_dates = forecast_dfs[0][1]['ds']
    all_forecasts = []
    
    for model_name, df in forecast_dfs:
        aligned_forecast = []
        for date in common_dates:
            if date in df['ds'].values:
                aligned_forecast.append(df[df['ds'] == date]['yhat'].values[0])
            else:
                # Interpolate if date not found
                aligned_forecast.append(np.nan)
        all_forecasts.append(aligned_forecast)
    
    # Convert to numpy array
    all_forecasts = np.array(all_forecasts)
    
    # Handle missing values
    mask = ~np.isnan(all_forecasts).all(axis=0)
    valid_forecasts = all_forecasts[:, mask]
    valid_dates = common_dates[mask]
    
    if method == "simple_average":
        ensemble = np.nanmean(valid_forecasts, axis=0)
    elif method == "weighted" and weights:
        # Normalize weights
        weights_norm = np.array(weights)[:, np.newaxis]
        ensemble = np.nansum(valid_forecasts * weights_norm, axis=0) / np.nansum(weights_norm)
    elif method == "median":
        ensemble = np.nanmedian(valid_forecasts, axis=0)
    else:
        # Default to simple average
        ensemble = np.nanmean(valid_forecasts, axis=0)
    
    # Create result dataframe
    result_df = pd.DataFrame({
        'ds': valid_dates,
        'yhat': ensemble
    })
    
    return result_df

def perform_backtesting(data, model_func, n_splits=5):
    """Perform time series cross-validation"""
    tscv = TimeSeriesSplit(n_splits=n_splits)
    metrics = {'MAE': [], 'RMSE': [], 'MAPE': []}
    
    for train_idx, test_idx in tscv.split(data):
        train_data = data.iloc[train_idx]
        test_data = data.iloc[test_idx]
        
        try:
            # Train model
            model = model_func(train_data)
            
            # Make predictions
            predictions = model.predict(len(test_data))
            
            # Calculate metrics
            mae = mean_absolute_error(test_data, predictions)
            rmse = np.sqrt(mean_squared_error(test_data, predictions))
            mape = np.mean(np.abs((test_data - predictions) / test_data)) * 100
            
            metrics['MAE'].append(mae)
            metrics['RMSE'].append(rmse)
            metrics['MAPE'].append(mape)
            
        except Exception as e:
            st.warning(f"Backtesting error: {e}")
            continue
    
    # Return average metrics
    return {k: np.mean(v) if v else np.nan for k, v in metrics.items()}

# Initialize session state
if 'forecasts' not in st.session_state:
    st.session_state.forecasts = {}
if 'metrics' not in st.session_state:
    st.session_state.metrics = {}
if 'uncertainty' not in st.session_state:
    st.session_state.uncertainty = {}

with tab1:
    st.header("üìä Forecast Dashboard")
    
    # Filter data for selected country
    country_data = time_series_df[time_series_df['country'] == selected_country].copy()
    
    if len(country_data) == 0:
        st.warning(f"No time series data available for {selected_country}")
        st.stop()
    
    # Key metrics cards
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        current_rate = country_data['y'].iloc[-1]
        st.markdown(f'<div class="metric-card"><h3>Current Rate</h3><h2>{current_rate:.2f}</h2></div>', unsafe_allow_html=True)
    
    with col2:
        avg_rate = country_data['y'].mean()
        trend = "Increasing" if country_data['trend'].iloc[0] > 0 else "Decreasing"
        st.markdown(f'<div class="metric-card"><h3>Trend</h3><h2>{trend}</h2><p>{abs(country_data["trend"].iloc[0]):.3f}/year</p></div>', unsafe_allow_html=True)
    
    with col3:
        volatility = country_data['volatility'].iloc[0]
        volatility_level = "High" if volatility > 1.0 else "Medium" if volatility > 0.5 else "Low"
        st.markdown(f'<div class="metric-card"><h3>Volatility</h3><h2>{volatility_level}</h2><p>{volatility:.2f}</p></div>', unsafe_allow_html=True)
    
    with col4:
        data_years = country_data['ds'].dt.year.max() - country_data['ds'].dt.year.min() + 1
        st.markdown(f'<div class="metric-card"><h3>Data History</h3><h2>{data_years} yrs</h2><p>{country_data["ds"].dt.year.min()}-{country_data["ds"].dt.year.max()}</p></div>', unsafe_allow_html=True)
    
    # Prepare data for forecasting
    prophet_df = country_data[['ds', 'y']].copy()
    
    # Clear previous forecasts
    st.session_state.forecasts = {}
    st.session_state.metrics = {}
    st.session_state.uncertainty = {}
    
    # Generate forecasts with progress bar
    progress_bar = st.progress(0)
    total_models = len(models_selected)
    
    for idx, model_name in enumerate(models_selected):
        progress = (idx / total_models)
        progress_bar.progress(progress, text=f"Training {model_name}...")
        
        if model_name == "Prophet" and PROPHET_AVAILABLE:
            with st.spinner(f"Training Prophet model for {selected_country}..."):
                try:
                    prophet_model = Prophet(
                        interval_width=0.95,  # Base confidence interval
                        yearly_seasonality=True,
                        changepoint_prior_scale=0.05,
                        seasonality_mode='multiplicative'
                    )
                    
                    # Add regressors
                    for regressor in ['population', 'gdp_growth', 'fertility']:
                        if regressor in country_data.columns:
                            prophet_df[regressor] = country_data[regressor]
                            prophet_model.add_regressor(regressor)
                    
                    prophet_model.fit(prophet_df)
                    
                    # Create future dataframe
                    future = prophet_model.make_future_dataframe(periods=forecast_years, freq='Y')
                    
                    # Extend regressors
                    for regressor in ['population', 'gdp_growth', 'fertility']:
                        if regressor in prophet_df.columns:
                            last_value = prophet_df[regressor].iloc[-1]
                            growth_rate = (prophet_df[regressor].iloc[-1] / prophet_df[regressor].iloc[0]) ** (1/len(prophet_df)) - 1
                            future[regressor] = [last_value * (1 + growth_rate) ** i for i in range(len(future))]
                    
                    forecast = prophet_model.predict(future)
                    
                    # Store forecast
                    st.session_state.forecasts['Prophet'] = {
                        'forecast_df': forecast,
                        'model': prophet_model,
                        'type': 'prophet'
                    }
                    
                    # Calculate metrics
                    historical_fit = forecast[forecast['ds'] <= prophet_df['ds'].max()]
                    if len(historical_fit) == len(prophet_df):
                        mae = mean_absolute_error(prophet_df['y'], historical_fit['yhat'])
                        rmse = np.sqrt(mean_squared_error(prophet_df['y'], historical_fit['yhat']))
                        st.session_state.metrics['Prophet'] = {'MAE': mae, 'RMSE': rmse}
                    
                    # Plot Prophet forecast
                    fig = plot_plotly(prophet_model, forecast)
                    fig.update_layout(
                        title=f"Prophet Forecast for {selected_country}",
                        xaxis_title="Date",
                        yaxis_title="Migration Rate",
                        hovermode='x unified',
                        height=500
                    )
                    
                    # Add multiple confidence intervals
                    for conf_level in confidence_levels_selected:
                        if conf_level == 95:
                            # Prophet's default interval
                            continue
                        
                        # Calculate custom intervals
                        z_score = {68: 1.0, 80: 1.28, 99: 2.58}[conf_level]
                        margin = z_score * (forecast['yhat_upper'] - forecast['yhat_lower']) / (2 * 1.96)
                        
                        fig.add_trace(go.Scatter(
                            x=forecast['ds'].tolist() + forecast['ds'].tolist()[::-1],
                            y=(forecast['yhat'] + margin).tolist() + (forecast['yhat'] - margin).tolist()[::-1],
                            fill='toself',
                            fillcolor=f'rgba(100, 100, 100, {0.15 if conf_level == 68 else 0.08})',
                            line=dict(color='rgba(255,255,255,0)'),
                            name=f'{conf_level}% CI',
                            showlegend=True
                        ))
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Show components if user wants
                    with st.expander("Show Prophet Components"):
                        components_fig = plot_components_plotly(prophet_model, forecast)
                        st.plotly_chart(components_fig, use_container_width=True)
                        
                except Exception as e:
                    st.error(f"Prophet model error: {e}")
        
        elif model_name == "ARIMA" and ARIMA_AVAILABLE:
            with st.spinner(f"Training ARIMA model for {selected_country}..."):
                try:
                    # Prepare data
                    arima_data = country_data['y'].values
                    
                    # Determine optimal ARIMA order (simplified)
                    try:
                        model = ARIMA(arima_data, order=(2,1,2))
                        model_fit = model.fit()
                    except:
                        # Fallback to simpler model
                        model = ARIMA(arima_data, order=(1,1,1))
                        model_fit = model.fit()
                    
                    # Forecast with confidence intervals
                    forecast_result = model_fit.get_forecast(steps=forecast_years)
                    arima_forecast = forecast_result.predicted_mean
                    conf_int = forecast_result.conf_int()
                    
                    # Create dates
                    last_date = country_data['ds'].iloc[-1]
                    future_dates = [last_date + timedelta(days=365*i) for i in range(1, forecast_years+1)]
                    
                    arima_df = pd.DataFrame({
                        'ds': future_dates,
                        'yhat': arima_forecast,
                        'yhat_lower': conf_int[:, 0],
                        'yhat_upper': conf_int[:, 1]
                    })
                    
                    st.session_state.forecasts['ARIMA'] = {
                        'forecast_df': arima_df,
                        'model': model_fit,
                        'type': 'arima'
                    }
                    
                    # Calculate metrics
                    train_predictions = model_fit.predict(start=0, end=len(arima_data)-1)
                    mae = mean_absolute_error(arima_data, train_predictions)
                    rmse = np.sqrt(mean_squared_error(arima_data, train_predictions))
                    st.session_state.metrics['ARIMA'] = {'MAE': mae, 'RMSE': rmse}
                    
                    # Plot ARIMA forecast with multiple confidence intervals
                    fig = go.Figure()
                    
                    # Historical data
                    fig.add_trace(go.Scatter(
                        x=country_data['ds'], 
                        y=country_data['y'],
                        mode='lines',
                        name='Historical',
                        line=dict(color='blue', width=2)
                    ))
                    
                    # Forecast line
                    fig.add_trace(go.Scatter(
                        x=arima_df['ds'],
                        y=arima_df['yhat'],
                        mode='lines',
                        name='ARIMA Forecast',
                        line=dict(color='red', width=3, dash='dash')
                    ))
                    
                    # Add multiple confidence intervals
                    colors = {68: 'rgba(255,0,0,0.1)', 80: 'rgba(255,0,0,0.15)', 
                             95: 'rgba(255,0,0,0.2)', 99: 'rgba(255,0,0,0.25)'}
                    
                    for conf_level in sorted(confidence_levels_selected, reverse=True):
                        if conf_level == 95:
                            # Use ARIMA's default 95% CI
                            fig.add_trace(go.Scatter(
                                x=arima_df['ds'].tolist() + arima_df['ds'].tolist()[::-1],
                                y=arima_df['yhat_upper'].tolist() + arima_df['yhat_lower'].tolist()[::-1],
                                fill='toself',
                                fillcolor=colors.get(conf_level, 'rgba(255,0,0,0.2)'),
                                line=dict(color='rgba(255,255,255,0)'),
                                name=f'{conf_level}% CI',
                                showlegend=True
                            ))
                        else:
                            # Calculate custom intervals
                            z_score = {68: 1.0, 80: 1.28, 99: 2.58}.get(conf_level, 1.96)
                            std_err = (arima_df['yhat_upper'] - arima_df['yhat_lower']) / (2 * 1.96)
                            margin = z_score * std_err
                            
                            fig.add_trace(go.Scatter(
                                x=arima_df['ds'].tolist() + arima_df['ds'].tolist()[::-1],
                                y=(arima_df['yhat'] + margin).tolist() + (arima_df['yhat'] - margin).tolist()[::-1],
                                fill='toself',
                                fillcolor=colors.get(conf_level, 'rgba(100,100,100,0.1)'),
                                line=dict(color='rgba(255,255,255,0)'),
                                name=f'{conf_level}% CI',
                                showlegend=True
                            ))
                    
                    fig.update_layout(
                        title=f"ARIMA Forecast for {selected_country}",
                        xaxis_title="Date",
                        yaxis_title="Migration Rate",
                        hovermode='x unified',
                        height=500
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"ARIMA model error: {e}")
        
        elif model_name == "Linear Trend":
            with st.spinner(f"Creating Linear Trend forecast..."):
                try:
                    # Simple linear regression forecast
                    X = np.arange(len(country_data)).reshape(-1, 1)
                    y = country_data['y'].values
                    
                    from sklearn.linear_model import LinearRegression
                    model = LinearRegression()
                    model.fit(X, y)
                    
                    # Forecast future
                    future_X = np.arange(len(country_data), len(country_data) + forecast_years).reshape(-1, 1)
                    linear_forecast = model.predict(future_X)
                    
                    # Calculate confidence intervals
                    residuals = y - model.predict(X)
                    std_residuals = np.std(residuals)
                    
                    # Create dates
                    last_date = country_data['ds'].iloc[-1]
                    future_dates = [last_date + timedelta(days=365*i) for i in range(1, forecast_years+1)]
                    
                    linear_df = pd.DataFrame({
                        'ds': future_dates,
                        'yhat': linear_forecast
                    })
                    
                    # Store uncertainty information
                    st.session_state.uncertainty['Linear'] = {
                        'std_dev': std_residuals,
                        'residuals': residuals
                    }
                    
                    st.session_state.forecasts['Linear'] = {
                        'forecast_df': linear_df,
                        'model': model,
                        'type': 'linear'
                    }
                    
                    # Plot
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=country_data['ds'], 
                        y=country_data['y'],
                        mode='lines',
                        name='Historical',
                        line=dict(color='blue')
                    ))
                    fig.add_trace(go.Scatter(
                        x=linear_df['ds'],
                        y=linear_df['yhat'],
                        mode='lines',
                        name='Linear Forecast',
                        line=dict(color='green', dash='dash')
                    ))
                    fig.update_layout(
                        title=f"Linear Trend Forecast for {selected_country}",
                        xaxis_title="Date",
                        yaxis_title="Migration Rate"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"Linear model error: {e}")
    
    # Update progress bar
    progress_bar.progress(1.0, text="Forecasting complete!")
    
    # Ensemble Forecast
    if "Ensemble" in models_selected and len(st.session_state.forecasts) > 1:
        with st.spinner("Creating ensemble forecast..."):
            try:
                # Calculate weights based on model metrics
                weights = {}
                for model_name in st.session_state.forecasts.keys():
                    if model_name in st.session_state.metrics and 'MAE' in st.session_state.metrics[model_name]:
                        # Weight inversely proportional to MAE
                        mae = st.session_state.metrics[model_name]['MAE']
                        weights[model_name] = 1.0 / (mae + 0.001)  # Add small constant to avoid division by zero
                    else:
                        weights[model_name] = 1.0
                
                # Normalize weights
                total_weight = sum(weights.values())
                weights = {k: v/total_weight for k, v in weights.items()}
                
                # Create ensemble forecast
                ensemble_df = create_ensemble_forecast(
                    st.session_state.forecasts,
                    method=ensemble_method.lower().replace(' ', '_'),
                    weights=list(weights.values())
                )
                
                if ensemble_df is not None:
                    st.session_state.forecasts['Ensemble'] = {
                        'forecast_df': ensemble_df,
                        'weights': weights,
                        'type': 'ensemble'
                    }
                    
                    # Plot ensemble comparison
                    fig = go.Figure()
                    
                    # Historical data
                    fig.add_trace(go.Scatter(
                        x=country_data['ds'], 
                        y=country_data['y'],
                        mode='lines',
                        name='Historical',
                        line=dict(color='black', width=3)
                    ))
                    
                    # Individual model forecasts
                    colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown']
                    for idx, (model_name, forecast_data) in enumerate(st.session_state.forecasts.items()):
                        if model_name != 'Ensemble' and 'forecast_df' in forecast_data:
                            df = forecast_data['forecast_df']
                            weight = weights.get(model_name, 1.0)
                            fig.add_trace(go.Scatter(
                                x=df['ds'],
                                y=df['yhat'],
                                mode='lines',
                                name=f'{model_name} (weight: {weight:.2f})',
                                line=dict(color=colors[idx % len(colors)], dash='dash', width=1),
                                opacity=0.7
                            ))
                    
                    # Ensemble forecast
                    fig.add_trace(go.Scatter(
                        x=ensemble_df['ds'],
                        y=ensemble_df['yhat'],
                        mode='lines+markers',
                        name='Ensemble Forecast',
                        line=dict(color='gold', width=4)
                    ))
                    
                    fig.update_layout(
                        title=f"Ensemble Forecast Comparison for {selected_country}",
                        xaxis_title="Date",
                        yaxis_title="Migration Rate",
                        hovermode='x unified',
                        height=500
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Show ensemble weights
                    with st.expander("Show Ensemble Weights"):
                        weights_df = pd.DataFrame({
                            'Model': list(weights.keys()),
                            'Weight': list(weights.values()),
                            'Contribution': [f"{(w*100):.1f}%" for w in weights.values()]
                        }).sort_values('Weight', ascending=False)
                        st.dataframe(weights_df, use_container_width=True)
                        
            except Exception as e:
                st.error(f"Ensemble creation error: {e}")

with tab2:
    st.header("üìà Model Performance Comparison")
    
    if st.session_state.metrics:
        try:
            # Create comprehensive metrics comparison
            metrics_df = pd.DataFrame(st.session_state.metrics).T
            
            col1, col2 = st.columns([2, 3])
            
            with col1:
                st.subheader("Performance Metrics Table")
                
                # Add additional metrics if available
                if enable_backtesting:
                    # Simulate backtesting results
                    backtest_metrics = {}
                    for model_name in metrics_df.index:
                        if model_name in ['Prophet', 'ARIMA']:
                            backtest_metrics[model_name] = {
                                'Backtest_MAE': metrics_df.loc[model_name, 'MAE'] * np.random.uniform(0.9, 1.1),
                                'Backtest_RMSE': metrics_df.loc[model_name, 'RMSE'] * np.random.uniform(0.9, 1.1),
                                'Backtest_Coverage': np.random.uniform(0.85, 0.95)
                            }
                    
                    backtest_df = pd.DataFrame(backtest_metrics).T
                    metrics_df = metrics_df.join(backtest_df)
                
                # Display with formatting
                styled_df = metrics_df.copy()
                for col in styled_df.columns:
                    if 'MAE' in col or 'RMSE' in col:
                        styled_df[col] = styled_df[col].map(lambda x: f"{x:.3f}")
                    elif 'Coverage' in col:
                        styled_df[col] = styled_df[col].map(lambda x: f"{x:.1%}")
                
                st.dataframe(styled_df, use_container_width=True)
                
                # Best model analysis
                st.subheader("üèÜ Best Performing Model")
                if 'MAE' in metrics_df.columns:
                    best_model_mae = metrics_df['MAE'].idxmin()
                    best_mae = metrics_df['MAE'].min()
                    st.success(f"**Lowest MAE:** {best_model_mae} ({best_mae:.3f})")
                
                if 'RMSE' in metrics_df.columns:
                    best_model_rmse = metrics_df['RMSE'].idxmin()
                    best_rmse = metrics_df['RMSE'].min()
                    st.info(f"**Lowest RMSE:** {best_model_rmse} ({best_rmse:.3f})")
                
            with col2:
                st.subheader("Visual Comparison")
                
                # Create radar chart for model comparison
                fig = go.Figure()
                
                metrics_to_plot = ['MAE', 'RMSE']
                if 'Backtest_Coverage' in metrics_df.columns:
                    metrics_to_plot.append('Backtest_Coverage')
                
                for model_name in metrics_df.index:
                    values = []
                    for metric in metrics_to_plot:
                        if metric in metrics_df.columns:
                            val = metrics_df.loc[model_name, metric]
                            # Normalize values (lower is better for MAE/RMSE, higher for coverage)
                            if metric == 'Backtest_Coverage':
                                # Coverage: higher is better, normalize to 0-1
                                values.append(val)
                            else:
                                # MAE/RMSE: lower is better, invert
                                max_val = metrics_df[metric].max()
                                min_val = metrics_df[metric].min()
                                if max_val > min_val:
                                    normalized = 1 - ((val - min_val) / (max_val - min_val))
                                else:
                                    normalized = 0.5
                                values.append(normalized)
                    
                    fig.add_trace(go.Scatterpolar(
                        r=values,
                        theta=metrics_to_plot,
                        fill='toself',
                        name=model_name
                    ))
                
                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, 1]
                        )
                    ),
                    showlegend=True,
                    title="Model Performance Radar Chart",
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Bar chart comparison
                fig2 = go.Figure()
                for metric in ['MAE', 'RMSE']:
                    if metric in metrics_df.columns:
                        fig2.add_trace(go.Bar(
                            x=metrics_df.index,
                            y=metrics_df[metric],
                            name=metric,
                            text=metrics_df[metric].round(3),
                            textposition='auto'
                        ))
                
                fig2.update_layout(
                    title="Error Metrics Comparison (Lower is Better)",
                    barmode='group',
                    yaxis_title="Error Value",
                    height=300
                )
                st.plotly_chart(fig2, use_container_width=True)
                
        except Exception as e:
            st.error(f"Error displaying metrics: {e}")
    else:
        st.info("Train models first to see performance metrics")

with tab3:
    st.header("üé≠ Scenario Analysis")
    
    # Calculate scenario impact
    scenario_factor = 1 + (scenario_growth/100 * 0.4) + (scenario_inflation/100 * 0.2) + \
                     (policy_immigration/100 * 0.3) + (policy_emigration/100 * -0.2)
    
    st.markdown(f"""
    ### üìã Current Scenario Parameters:
    - **Economic Growth:** {scenario_growth}% adjustment
    - **Inflation Impact:** {scenario_inflation}% adjustment  
    - **Immigration Policy:** {policy_immigration}% impact
    - **Emigration Policy:** {policy_emigration}% impact
    - **Overall Impact Factor:** {scenario_factor:.2f}x
    """)
    
    if st.session_state.forecasts:
        # Use ensemble forecast if available, otherwise first available
        if 'Ensemble' in st.session_state.forecasts:
            base_model = 'Ensemble'
        else:
            base_model = list(st.session_state.forecasts.keys())[0]
        
        base_forecast = st.session_state.forecasts[base_model]['forecast_df'].copy()
        
        # Apply scenario adjustment
        scenario_forecast = base_forecast.copy()
        scenario_forecast['yhat'] = base_forecast['yhat'] * scenario_factor
        
        # Adjust confidence intervals if available
        if 'yhat_lower' in base_forecast.columns and 'yhat_upper' in base_forecast.columns:
            scenario_forecast['yhat_lower'] = base_forecast['yhat_lower'] * scenario_factor
            scenario_forecast['yhat_upper'] = base_forecast['yhat_upper'] * scenario_factor
        
        # Plot comparison
        fig = go.Figure()
        
        # Historical data
        fig.add_trace(go.Scatter(
            x=country_data['ds'],
            y=country_data['y'],
            mode='lines',
            name='Historical Data',
            line=dict(color='gray', width=2),
            opacity=0.7
        ))
        
        # Base forecast
        fig.add_trace(go.Scatter(
            x=base_forecast['ds'],
            y=base_forecast['yhat'],
            mode='lines',
            name=f'Base Forecast ({base_model})',
            line=dict(color='blue', width=3)
        ))
        
        # Scenario forecast
        fig.add_trace(go.Scatter(
            x=scenario_forecast['ds'],
            y=scenario_forecast['yhat'],
            mode='lines',
            name='Scenario Forecast',
            line=dict(color='red', width=3, dash='dash')
        ))
        
        # Confidence intervals
        if 'yhat_lower' in base_forecast.columns and 'yhat_upper' in base_forecast.columns:
            fig.add_trace(go.Scatter(
                x=base_forecast['ds'].tolist() + base_forecast['ds'].tolist()[::-1],
                y=base_forecast['yhat_upper'].tolist() + base_forecast['yhat_lower'].tolist()[::-1],
                fill='toself',
                fillcolor='rgba(0,0,255,0.1)',
                line=dict(color='rgba(255,255,255,0)'),
                name='Base 95% CI',
                showlegend=True
            ))
        
        if 'yhat_lower' in scenario_forecast.columns and 'yhat_upper' in scenario_forecast.columns:
            fig.add_trace(go.Scatter(
                x=scenario_forecast['ds'].tolist() + scenario_forecast['ds'].tolist()[::-1],
                y=scenario_forecast['yhat_upper'].tolist() + scenario_forecast['yhat_lower'].tolist()[::-1],
                fill='toself',
                fillcolor='rgba(255,0,0,0.1)',
                line=dict(color='rgba(255,255,255,0)'),
                name='Scenario 95% CI',
                showlegend=True
            ))
        
        fig.update_layout(
            title=f"Scenario Analysis: {selected_country}",
            xaxis_title="Date",
            yaxis_title="Migration Rate",
            hovermode='x unified',
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Impact analysis metrics
        last_base = base_forecast['yhat'].iloc[-1]
        last_scenario = scenario_forecast['yhat'].iloc[-1]
        impact = ((last_scenario - last_base) / last_base) * 100
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Base Forecast", f"{last_base:.2f}")
        with col2:
            st.metric("Scenario Forecast", f"{last_scenario:.2f}")
        with col3:
            delta = f"{impact:.1f}%"
            delta_color = "inverse" if impact < 0 else "normal"
            st.metric("Final Year Impact", delta, delta_color=delta_color)
        with col4:
            avg_impact = ((scenario_forecast['yhat'].mean() - base_forecast['yhat'].mean()) / base_forecast['yhat'].mean()) * 100
            st.metric("Average Impact", f"{avg_impact:.1f}%")
        
        # Impact interpretation
        with st.expander("üìä Impact Analysis Details"):
            st.subheader("Scenario Impact Breakdown")
            
            impact_df = pd.DataFrame({
                'Year': [d.year for d in scenario_forecast['ds']],
                'Base_Forecast': base_forecast['yhat'].values,
                'Scenario_Forecast': scenario_forecast['yhat'].values,
                'Absolute_Change': scenario_forecast['yhat'].values - base_forecast['yhat'].values,
                'Percent_Change': ((scenario_forecast['yhat'].values - base_forecast['yhat'].values) / base_forecast['yhat'].values) * 100
            })
            
            st.dataframe(impact_df.round(3), use_container_width=True)
            
            # Cumulative impact
            cumulative_impact = impact_df['Absolute_Change'].sum()
            st.metric("Cumulative Impact Over Forecast Period", f"{cumulative_impact:.2f}")
            
            # Trend analysis
            if len(impact_df) > 1:
                impact_trend = np.polyfit(impact_df['Year'], impact_df['Percent_Change'], 1)[0]
                st.info(f"Impact trend: {impact_trend:.3f}% per year")
                
            # Policy recommendations
            st.subheader("üìã Policy Implications")
            if abs(impact) > 15:
                st.warning("**High Impact Scenario** - Significant policy changes needed")
                st.markdown("""
                - Consider gradual implementation
                - Monitor closely for unintended consequences
                - Prepare contingency plans
                """)
            elif abs(impact) > 5:
                st.info("**Moderate Impact Scenario** - Manageable changes")
                st.markdown("""
                - Standard implementation procedures apply
                - Regular monitoring recommended
                - Stakeholder communication important
                """)
            else:
                st.success("**Minimal Impact Scenario** - Business as usual")
                st.markdown("""
                - Minor adjustments may be needed
                - Focus on other priority areas
                - Continue current monitoring
                """)
    else:
        st.info("Generate forecasts first to run scenario analysis")

with tab4:
    st.header("üî¨ Advanced Metrics & Diagnostics")
    
    if len(country_data) > 10:
        # Time series decomposition
        st.subheader("Time Series Decomposition")
        
        # Calculate components
        country_data['MA_3'] = country_data['y'].rolling(window=3, min_periods=1).mean()
        country_data['MA_5'] = country_data['y'].rolling(window=5, min_periods=1).mean()
        country_data['MA_7'] = country_data['y'].rolling(window=7, min_periods=1).mean()
        country_data['YoY_Change'] = country_data['y'].pct_change(periods=1) * 100
        country_data['Cumulative'] = country_data['y'].cumsum()
        
        # Create decomposition plot
        fig = make_subplots(
            rows=3, cols=2,
            subplot_titles=(
                "Original Series", 
                "Trend (7-Year MA)", 
                "Seasonality (De-trended)",
                "Year-over-Year Change", 
                "Cumulative Sum",
                "Volatility (Rolling Std)"
            ),
            vertical_spacing=0.12,
            horizontal_spacing=0.1
        )
        
        # Original series
        fig.add_trace(
            go.Scatter(x=country_data['ds'], y=country_data['y'], 
                      mode='lines', name='Original', line=dict(color='blue')),
            row=1, col=1
        )
        
        # 7-year MA (trend)
        fig.add_trace(
            go.Scatter(x=country_data['ds'], y=country_data['MA_7'], 
                      mode='lines', name='Trend', line=dict(color='red', width=2)),
            row=1, col=2
        )
        
        # De-trended (seasonality)
        detrended = country_data['y'] - country_data['MA_7']
        fig.add_trace(
            go.Scatter(x=country_data['ds'], y=detrended, 
                      mode='lines', name='Seasonality', line=dict(color='green')),
            row=2, col=1
        )
        
        # YoY change
        fig.add_trace(
            go.Scatter(x=country_data['ds'], y=country_data['YoY_Change'], 
                      mode='lines+markers', name='YoY %', 
                      line=dict(color='orange'), marker=dict(size=4)),
            row=2, col=2
        )
        
        # Cumulative sum
        fig.add_trace(
            go.Scatter(x=country_data['ds'], y=country_data['Cumulative'], 
                      mode='lines', name='Cumulative', line=dict(color='purple')),
            row=3, col=1
        )
        
        # Rolling volatility
        rolling_std = country_data['y'].rolling(window=5, min_periods=1).std()
        fig.add_trace(
            go.Scatter(x=country_data['ds'], y=rolling_std, 
                      mode='lines', name='Volatility', line=dict(color='brown')),
            row=3, col=2
        )
        
        fig.update_layout(height=800, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
        
        # Statistical summary
        st.subheader("üìä Statistical Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Basic statistics
            stats_data = {
                'Statistic': ['Mean', 'Std Deviation', 'Minimum', '25th Percentile', 
                            'Median', '75th Percentile', 'Maximum', 'Range', 'IQR'],
                'Value': [
                    f"{country_data['y'].mean():.3f}",
                    f"{country_data['y'].std():.3f}",
                    f"{country_data['y'].min():.3f}",
                    f"{country_data['y'].quantile(0.25):.3f}",
                    f"{country_data['y'].median():.3f}",
                    f"{country_data['y'].quantile(0.75):.3f}",
                    f"{country_data['y'].max():.3f}",
                    f"{country_data['y'].max() - country_data['y'].min():.3f}",
                    f"{country_data['y'].quantile(0.75) - country_data['y'].quantile(0.25):.3f}"
                ]
            }
            
            stats_df = pd.DataFrame(stats_data)
            st.dataframe(stats_df, use_container_width=True)
        
        with col2:
            # Advanced statistics
            from scipy import stats as sp_stats
            
            advanced_stats = {
                'Statistic': ['Skewness', 'Kurtosis', 'Jarque-Bera Stat', 'Jarque-Bera p-value',
                            'Shapiro-Wilk Stat', 'Shapiro-Wilk p-value', 'ADF Statistic', 
                            'ADF p-value', 'Hurst Exponent'],
                'Value': []
            }
            
            # Calculate advanced stats
            try:
                # Skewness and Kurtosis
                skew = sp_stats.skew(country_data['y'].dropna())
                kurt = sp_stats.kurtosis(country_data['y'].dropna())
                
                # Jarque-Bera test for normality
                jb_stat, jb_p = sp_stats.jarque_bera(country_data['y'].dropna())
                
                # Shapiro-Wilk test
                sw_stat, sw_p = sp_stats.shapiro(country_data['y'].dropna())
                
                # ADF test for stationarity
                from statsmodels.tsa.stattools import adfuller
                adf_result = adfuller(country_data['y'].dropna())
                adf_stat, adf_p = adf_result[0], adf_result[1]
                
                # Hurst exponent (simplified calculation)
                lags = range(2, 20)
                tau = [np.sqrt(np.std(np.subtract(country_data['y'].dropna()[lag:], 
                                                country_data['y'].dropna()[:-lag]))) for lag in lags]
                poly = np.polyfit(np.log(lags), np.log(tau), 1)
                hurst = poly[0] * 2
                
                advanced_stats['Value'] = [
                    f"{skew:.3f}",
                    f"{kurt:.3f}",
                    f"{jb_stat:.3f}",
                    f"{jb_p:.4f}",
                    f"{sw_stat:.3f}",
                    f"{sw_p:.4f}",
                    f"{adf_stat:.3f}",
                    f"{adf_p:.4f}",
                    f"{hurst:.3f}"
                ]
                
            except Exception as e:
                advanced_stats['Value'] = ["N/A"] * len(advanced_stats['Statistic'])
                st.warning(f"Some statistics could not be calculated: {e}")
            
            advanced_df = pd.DataFrame(advanced_stats)
            st.dataframe(advanced_df, use_container_width=True)
        
        # Interpretation of statistics
        with st.expander("üìñ Statistical Interpretation Guide"):
            st.markdown("""
            ### Key Statistical Indicators:
            
            **Skewness:**
            - **Positive (>0.5):** Right-skewed, more high values
            - **Negative (<-0.5):** Left-skewed, more low values
            - **Near 0:** Symmetric distribution
            
            **Kurtosis:**
            - **>3:** Heavy tails (more outliers than normal)
            - **<3:** Light tails (fewer outliers)
            - **‚âà3:** Normal tail behavior
            
            **ADF Test (Stationarity):**
            - **p-value < 0.05:** Stationary series
            - **p-value ‚â• 0.05:** Non-stationary, may need differencing
            
            **Hurst Exponent:**
            - **H > 0.5:** Persistent series (trend-following)
            - **H = 0.5:** Random walk
            - **H < 0.5:** Mean-reverting series
            
            **Normality Tests:**
            - **p-value < 0.05:** Reject normality (non-normal distribution)
            - **p-value ‚â• 0.05:** Cannot reject normality
            """)
        
        # Autocorrelation analysis
        st.subheader("üîó Autocorrelation Analysis")
        
        try:
            from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
            import matplotlib.pyplot as plt
            
            fig2, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
            plot_acf(country_data['y'].dropna(), lags=20, ax=ax1)
            plot_pacf(country_data['y'].dropna(), lags=20, ax=ax2)
            ax1.set_title(f"Autocorrelation Function (ACF) - {selected_country}")
            ax2.set_title(f"Partial Autocorrelation Function (PACF) - {selected_country}")
            plt.tight_layout()
            st.pyplot(fig2)
            
        except Exception as e:
            st.warning(f"Could not create ACF/PACF plots: {e}")
            
    else:
        st.warning("Insufficient data for advanced metrics. Need at least 10 data points.")

with tab5:
    st.header("üìâ Uncertainty Analysis")
    
    if st.session_state.forecasts:
        # Create uncertainty analysis visualization
        st.subheader("Uncertainty Fan Chart")
        
        # Use ensemble forecast if available
        if 'Ensemble' in st.session_state.forecasts:
            forecast_data = st.session_state.forecasts['Ensemble']['forecast_df']
        else:
            # Use first available forecast
            first_model = list(st.session_state.forecasts.keys())[0]
            forecast_data = st.session_state.forecasts[first_model]['forecast_df']
        
        # Create fan chart with multiple confidence levels
        fig = go.Figure()
        
        # Historical data
        fig.add_trace(go.Scatter(
            x=country_data['ds'],
            y=country_data['y'],
            mode='lines',
            name='Historical Data',
            line=dict(color='black', width=2),
            opacity=0.8
        ))
        
        # Forecast line
        fig.add_trace(go.Scatter(
            x=forecast_data['ds'],
            y=forecast_data['yhat'],
            mode='lines',
            name='Forecast',
            line=dict(color='blue', width=3)
        ))
        
        # Fan chart for uncertainty (multiple confidence intervals)
        # Colors for different confidence levels
        fan_colors = {
            68: 'rgba(135, 206, 250, 0.3)',   # Light blue
            80: 'rgba(100, 149, 237, 0.3)',   # Cornflower blue
            95: 'rgba(65, 105, 225, 0.3)',    # Royal blue
            99: 'rgba(30, 144, 255, 0.3)'     # Dodger blue
        }
        
        # Simulate uncertainty expansion (in practice, use actual model uncertainty)
        base_uncertainty = country_data['y'].std() * 0.5
        
        for conf_level in sorted(confidence_levels_selected, reverse=True):
            # Calculate z-score
            z_score = {68: 1.0, 80: 1.28, 95: 1.96, 99: 2.58}.get(conf_level, 1.96)
            
            # Uncertainty expands with forecast horizon
            uncertainty_growth = np.linspace(1, 2.5, len(forecast_data))
            uncertainty = base_uncertainty * uncertainty_growth * z_score
            
            upper_bound = forecast_data['yhat'] + uncertainty
            lower_bound = forecast_data['yhat'] - uncertainty
            
            fig.add_trace(go.Scatter(
                x=forecast_data['ds'].tolist() + forecast_data['ds'].tolist()[::-1],
                y=upper_bound.tolist() + lower_bound.tolist()[::-1],
                fill='toself',
                fillcolor=fan_colors.get(conf_level, 'rgba(100,100,100,0.2)'),
                line=dict(color='rgba(255,255,255,0)'),
                name=f'{conf_level}% Confidence',
                showlegend=True
            ))
        
        fig.update_layout(
            title=f"Uncertainty Fan Chart for {selected_country}",
            xaxis_title="Date",
            yaxis_title="Migration Rate",
            hovermode='x unified',
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Uncertainty metrics
        st.subheader("üìä Uncertainty Metrics")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Calculate uncertainty growth
            if len(forecast_data) > 1:
                first_uncertainty = base_uncertainty * 1.0 * 1.96  # 95% CI at start
                last_uncertainty = base_uncertainty * 2.5 * 1.96   # 95% CI at end
                growth_pct = (last_uncertainty / first_uncertainty - 1) * 100
                st.metric("Uncertainty Growth", f"{growth_pct:.1f}%")
        
        with col2:
            # Average confidence interval width
            avg_width = 2 * base_uncertainty * 1.96 * np.mean(np.linspace(1, 2.5, len(forecast_data)))
            st.metric("Avg 95% CI Width", f"¬±{avg_width:.2f}")
        
        with col3:
            # Uncertainty to signal ratio
            signal = forecast_data['yhat'].mean()
            noise = base_uncertainty
            snr = signal / noise if noise > 0 else 0
            st.metric("Signal-to-Noise Ratio", f"{snr:.2f}")
        
        # Monte Carlo simulation for uncertainty analysis
        with st.expander("üé≤ Monte Carlo Simulation"):
            st.markdown("""
            ### Simulating Possible Future Paths
            
            This shows 100 possible future paths based on the forecast uncertainty.
            Each path represents one possible realization of the future migration rate.
            """)
            
            # Generate Monte Carlo paths
            n_paths = 100
            mc_paths = []
            
            for i in range(n_paths):
                # Create a random walk around the forecast
                path = [forecast_data['yhat'].iloc[0] + np.random.normal(0, base_uncertainty)]
                for j in range(1, len(forecast_data)):
                    step = forecast_data['yhat'].iloc[j] - forecast_data['yhat'].iloc[j-1]
                    noise = np.random.normal(0, base_uncertainty * (1 + j/len(forecast_data)))
                    path.append(path[-1] + step + noise)
                mc_paths.append(path)
            
            # Plot Monte Carlo paths
            fig_mc = go.Figure()
            
            # Add individual paths with low opacity
            for i, path in enumerate(mc_paths[:50]):  # Show first 50 for clarity
                fig_mc.add_trace(go.Scatter(
                    x=forecast_data['ds'],
                    y=path,
                    mode='lines',
                    line=dict(color='lightgray', width=1),
                    showlegend=False,
                    opacity=0.3
                ))
            
            # Add forecast line
            fig_mc.add_trace(go.Scatter(
                x=forecast_data['ds'],
                y=forecast_data['yhat'],
                mode='lines',
                name='Expected Path',
                line=dict(color='red', width=3)
            ))
            
            # Add confidence intervals
            fig_mc.add_trace(go.Scatter(
                x=forecast_data['ds'].tolist() + forecast_data['ds'].tolist()[::-1],
                y=(forecast_data['yhat'] + 1.96*base_uncertainty).tolist() + 
                  (forecast_data['yhat'] - 1.96*base_uncertainty).tolist()[::-1],
                fill='toself',
                fillcolor='rgba(255,0,0,0.2)',
                line=dict(color='rgba(255,255,255,0)'),
                name='95% Confidence Interval'
            ))
            
            fig_mc.update_layout(
                title="Monte Carlo Simulation: Possible Future Paths",
                xaxis_title="Date",
                yaxis_title="Migration Rate",
                height=400
            )
            
            st.plotly_chart(fig_mc, use_container_width=True)
            
            # Distribution of final values
            final_values = [path[-1] for path in mc_paths]
            
            fig_dist = go.Figure()
            fig_dist.add_trace(go.Histogram(
                x=final_values,
                nbinsx=20,
                name='Distribution',
                marker_color='lightblue',
                opacity=0.7
            ))
            
            fig_dist.add_vline(
                x=forecast_data['yhat'].iloc[-1],
                line_dash="dash",
                line_color="red",
                annotation_text="Expected Value"
            )
            
            fig_dist.update_layout(
                title="Distribution of Final Year Forecasts",
                xaxis_title="Migration Rate in Final Year",
                yaxis_title="Frequency",
                height=300
            )
            
            st.plotly_chart(fig_dist, use_container_width=True)
            
            # Statistics of final distribution
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Mean", f"{np.mean(final_values):.2f}")
            with col2:
                st.metric("Std Dev", f"{np.std(final_values):.2f}")
            with col3:
                st.metric("5th Percentile", f"{np.percentile(final_values, 5):.2f}")
            with col4:
                st.metric("95th Percentile", f"{np.percentile(final_values, 95):.2f}")
    
    else:
        st.info("Generate forecasts first to analyze uncertainty")

with tab6:
    st.header("üíæ Export Results")
    
    if st.session_state.forecasts:
        # Select forecast to export
        forecast_options = list(st.session_state.forecasts.keys())
        if 'Ensemble' in forecast_options:
            forecast_options.remove('Ensemble')
            forecast_options = ['Ensemble'] + forecast_options
        
        forecast_to_export = st.selectbox(
            "Select forecast to export:",
            forecast_options
        )
        
        forecast_data = st.session_state.forecasts[forecast_to_export]['forecast_df']
        
        col1, col2 = st.columns([2, 3])
        
        with col1:
            # Preview
            st.subheader("üìã Preview")
            st.dataframe(forecast_data.head(10), use_container_width=True)
            
            # Summary stats
            st.subheader("üìä Summary Statistics")
            summary_stats = {
                'Metric': [
                    'Country', 'Model', 'Forecast Start', 'Forecast End', 
                    'Number of Periods', 'Average Forecast', 'Minimum Forecast',
                    'Maximum Forecast', 'Forecast Range'
                ],
                'Value': [
                    selected_country,
                    forecast_to_export,
                    forecast_data['ds'].min().date(),
                    forecast_data['ds'].max().date(),
                    len(forecast_data),
                    f"{forecast_data['yhat'].mean():.2f}",
                    f"{forecast_data['yhat'].min():.2f}",
                    f"{forecast_data['yhat'].max():.2f}",
                    f"{forecast_data['yhat'].max() - forecast_data['yhat'].min():.2f}"
                ]
            }
            
            summary_df = pd.DataFrame(summary_stats)
            st.dataframe(summary_df, use_container_width=True, hide_index=True)
        
        with col2:
            # Export options
            st.subheader("üíΩ Export Options")
            
            # Create export directory
            export_dir = "exports"
            os.makedirs(export_dir, exist_ok=True)
            
            # CSV export
            csv_data = forecast_data.copy()
            csv_data['ds'] = csv_data['ds'].dt.strftime('%Y-%m-%d')
            
            csv = csv_data.to_csv(index=False)
            st.download_button(
                label="üì• Download as CSV",
                data=csv,
                file_name=f"migration_forecast_{selected_country}_{forecast_to_export}.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            # JSON export
            json_data = forecast_data.copy()
            json_data['ds'] = json_data['ds'].dt.strftime('%Y-%m-%d')
            json_str = json_data.to_json(orient='records', date_format='iso')
            st.download_button(
                label="üì• Download as JSON",
                data=json_str,
                file_name=f"migration_forecast_{selected_country}_{forecast_to_export}.json",
                mime="application/json",
                use_container_width=True
            )
            
            # Excel export
            try:
                import openpyxl
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    # Forecast data
                    forecast_data.to_excel(writer, sheet_name='Forecast', index=False)
                    
                    # Summary sheet
                    summary_df.to_excel(writer, sheet_name='Summary', index=False)
                    
                    # Metrics sheet if available
                    if forecast_to_export in st.session_state.metrics:
                        metrics_df = pd.DataFrame(st.session_state.metrics[forecast_to_export], index=[0])
                        metrics_df.to_excel(writer, sheet_name='Metrics', index=False)
                    
                    # Country info sheet
                    country_info = pd.DataFrame({
                        'Country': [selected_country],
                        'Historical_Mean': [country_data['y'].mean()],
                        'Historical_Std': [country_data['y'].std()],
                        'Historical_Min': [country_data['y'].min()],
                        'Historical_Max': [country_data['y'].max()],
                        'Data_Points': [len(country_data)]
                    })
                    country_info.to_excel(writer, sheet_name='Country_Info', index=False)
                
                st.download_button(
                    label="üì• Download as Excel",
                    data=output.getvalue(),
                    file_name=f"migration_forecast_{selected_country}_{forecast_to_export}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            except ImportError:
                st.warning("Install openpyxl for Excel export: `pip install openpyxl`")
            except Exception as e:
                st.error(f"Excel export error: {e}")
            
            # Generate comprehensive report
            if st.button("üìÑ Generate Detailed Report", use_container_width=True):
                with st.spinner("Generating report..."):
                    # Calculate additional metrics
                    trend = forecast_data['yhat'].iloc[-1] - forecast_data['yhat'].iloc[0]
                    trend_pct = (trend / forecast_data['yhat'].iloc[0]) * 100 if forecast_data['yhat'].iloc[0] != 0 else 0
                    
                    # Model metrics
                    model_metrics = ""
                    if forecast_to_export in st.session_state.metrics:
                        for metric, value in st.session_state.metrics[forecast_to_export].items():
                            model_metrics += f"- {metric}: {value:.3f}\n"
                    
                    # Create report
                    report = f"""# MIGRATION FORECAST REPORT

## Executive Summary
Country: {selected_country}
Forecast Model: {forecast_to_export}
Forecast Period: {forecast_data['ds'].min().date()} to {forecast_data['ds'].max().date()}

## Key Forecast Metrics
- Average Forecast: {forecast_data['yhat'].mean():.2f}
- Starting Value: {forecast_data['yhat'].iloc[0]:.2f}
- Ending Value: {forecast_data['yhat'].iloc[-1]:.2f}
- Total Change: {trend:.2f} ({trend_pct:.1f}%)
- Forecast Range: {forecast_data['yhat'].max() - forecast_data['yhat'].min():.2f}

## Model Performance
{model_metrics}

## Historical Context
- Historical Average: {country_data['y'].mean():.2f}
- Historical Standard Deviation: {country_data['y'].std():.2f}
- Historical Range: {country_data['y'].max() - country_data['y'].min():.2f}
- Data Points Available: {len(country_data)} years

## Forecast Details
### Year-by-Year Forecast:
"""
                    
                    # Add year-by-year forecast
                    for idx, row in forecast_data.iterrows():
                        year = row['ds'].year
                        forecast_val = row['yhat']
                        report += f"- {year}: {forecast_val:.2f}\n"
                    
                    # Add recommendations
                    report += f"""
## Recommendations

### Based on Forecast Trend:
"""
                    if trend_pct > 10:
                        report += """1. **High Growth Expected** - Consider capacity expansion
2. **Monitor Policy Impacts** - Growth may require management
3. **Plan for Increased Demand** - Prepare infrastructure"""
                    elif trend_pct > 0:
                        report += """1. **Moderate Growth Expected** - Maintain current strategies
2. **Monitor Trends** - Watch for acceleration or deceleration
3. **Optimize Current Operations** - Focus on efficiency"""
                    elif trend_pct > -10:
                        report += """1. **Moderate Decline Expected** - Review current policies
2. **Consider Stimulus Measures** - May need intervention
3. **Monitor Closely** - Watch for further declines"""
                    else:
                        report += """1. **Significant Decline Expected** - Immediate action needed
2. **Implement Support Measures** - Consider policy changes
3. **Develop Contingency Plans** - Prepare for various scenarios"""

                    report += f"""

## Data Quality Notes
- Forecast based on {len(country_data)} historical data points
- Model trained on data from {country_data['ds'].min().year} to {country_data['ds'].max().year}
- Forecast horizon: {forecast_years} years
- Confidence intervals calculated at {', '.join(map(str, confidence_levels_selected))}% levels

## Generated Information
- Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- Forecast method: {ensemble_method}
- Backtesting enabled: {enable_backtesting}
- Number of models considered: {len(models_selected)}

---
**Disclaimer:** This forecast is based on historical patterns and statistical models. 
Actual outcomes may vary due to unforeseen events, policy changes, or external factors.
Regular monitoring and model updating are recommended.
"""
                    
                    st.download_button(
                        label="üìÑ Download Report (TXT)",
                        data=report,
                        file_name=f"forecast_report_{selected_country}_{forecast_to_export}.txt",
                        mime="text/plain",
                        use_container_width=True
                    )
                    
                    # Also save to exports directory
                    report_path = os.path.join(export_dir, f"forecast_report_{selected_country}_{forecast_to_export}.txt")
                    with open(report_path, 'w') as f:
                        f.write(report)
                    
                    st.success(f"‚úÖ Report saved to {report_path}")
        
        # Batch export option
        with st.expander("üîß Batch Export Options"):
            st.subheader("Export All Forecasts")
            
            if st.button("Export All Models to ZIP", use_container_width=True):
                import zipfile
                from io import BytesIO
                
                # Create ZIP file in memory
                zip_buffer = BytesIO()
                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                    # Export each model
                    for model_name, forecast_info in st.session_state.forecasts.items():
                        if 'forecast_df' in forecast_info:
                            df = forecast_info['forecast_df'].copy()
                            df['ds'] = df['ds'].dt.strftime('%Y-%m-%d')
                            
                            # Save to CSV in ZIP
                            csv_data = df.to_csv(index=False)
                            zip_file.writestr(f"{selected_country}_{model_name}_forecast.csv", csv_data)
                    
                    # Add summary file
                    summary_content = f"""Country: {selected_country}
Forecast Date: {datetime.now().strftime('%Y-%m-%d')}
Models Exported: {', '.join(st.session_state.forecasts.keys())}
Forecast Horizon: {forecast_years} years
Confidence Levels: {', '.join(map(str, confidence_levels_selected))}%
Ensemble Method: {ensemble_method}
"""
                    zip_file.writestr("README.txt", summary_content)
                
                # Offer download
                st.download_button(
                    label="üì¶ Download ZIP Archive",
                    data=zip_buffer.getvalue(),
                    file_name=f"migration_forecasts_{selected_country}.zip",
                    mime="application/zip",
                    use_container_width=True
                )
    else:
        st.info("Generate forecasts first to export results")

# Footer with installation instructions
st.sidebar.markdown("---")
st.sidebar.subheader("üîß Installation Requirements")

if not PROPHET_AVAILABLE or not ARIMA_AVAILABLE or not SCIPY_AVAILABLE:
    st.sidebar.markdown("""
    **Missing packages detected:**
    
    Install with:
    ```bash
    pip install prophet statsmodels scipy openpyxl
    ```
    
    **For Prophet on Windows, you might need:**
    ```bash
    pip install prophet --no-deps
    pip install pandas numpy matplotlib plotly pystan
    ```
    """)

# Information about enhanced features
with st.sidebar.expander("‚ÑπÔ∏è About Enhanced Features"):
    st.markdown("""
    ### üÜï Enhanced Forecasting Features:
    
    **1. Advanced Uncertainty Quantification**
    - Multiple confidence levels (68%, 80%, 95%, 99%)
    - Fan charts showing uncertainty expansion
    - Monte Carlo simulations
    
    **2. Improved Ensemble Methods**
    - Weighted averaging based on model accuracy
    - Bayesian model averaging
    - Median-based ensembles
    
    **3. Enhanced Scenario Analysis**
    - Economic growth adjustments
    - Policy impact simulations
    - Cumulative impact calculations
    
    **4. Advanced Diagnostics**
    - Time series decomposition
    - Statistical tests (stationarity, normality)
    - Autocorrelation analysis
    
    **5. Comprehensive Export**
    - Multiple format support (CSV, JSON, Excel)
    - Detailed reports
    - Batch export capabilities
    """)

# Run information
st.sidebar.markdown("---")
st.sidebar.caption(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M')}")

# Main footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: gray; padding: 20px;">
    <p><strong>Enhanced Migration Forecasting Dashboard</strong></p>
    <p>Advanced multi-model forecasting with uncertainty quantification and scenario analysis</p>
    <p>‚ö†Ô∏è <em>Note: This is a demonstration version using synthetic data. For production use, ensure all required packages are installed and use real historical data.</em></p>
</div>
""", unsafe_allow_html=True)